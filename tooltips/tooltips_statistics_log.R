#------Documentation and governance-----

#----DG1-----
#For some reason R does not like comments being over multiple lines
DG1tooltipstatistics <- "Specific note for statistics"

#----DG2----
DG2tooltipstatistics <- "1) Comprehensive user guide (or equivalent documentation within the analysis) enables analysis use, is easily found and up to date <br> <br> 2) User guide available and enables analysis use but some information is missing or it is not up to date <br> <br> 3) User guide not available, but running the analysis is easy and intuitive <br> <br> 4) User guide not available but a new user could understand key analysis functionalities relatively quickly <br> <br> 5) No documentation available to support the user who cannot understand how to run the analysis in a relatively short time period."

#----DG3----
DG3tooltipstatistics <- "1) Comprehensive and informative technical guide available and up to date <br> <br> 2) Technical guide available but some information is missing or it is not up to date. <br> <br> 3) Technical guide available but most information is missing or it is not up to date. <br> <br> 4) Technical guide not available, but some technical info can be found within the analysis <br> <br> 5) No technical documentation either in external document or within the analysis available to help users with future analysis adaptations."

#----DG4----
DG4tooltipstatistics <- "1) KIM protocols applied in full, including files stored in appropriate Office365 locations, with appropriate controlled access (only sensitive information not accessible by wider DfE colleagues). <br> <br> 2) KIM protocols applied, including files stored in appropriate Office365 locations, but access restricted more than DfE protocols advise. <br> <br> 3) Some KIM protocols applied, but files may not be stored in the most appropriate locations and/or access not widely granted. <br> <br> 4) No KIM protocols applied but files stored in a way that other analysts coming into the team would easily locate all relevant files. <br> <br> 5) No KIM protocols applied and files may be hard to locate."

#----DG5----
DG5tooltipstatistics <- "1) A version log exists and follows a clear and logical versioning system. Detailed information of the changes performed and their impacts are included. <br> <br> 2) Version log and labelling exist and are largely complete but there are a few gaps or inconsistencies. <br> <br> 3) A version log and labelling system exists but not all the versions were logged or the descriptions of the changes performed are limited <br> <br> 4) No version log, but a version labelling makes it clear which analysis version is used <br> <br> 5) No version log and no version labelling"

#----DG6----
DG6tooltipstatistics <- "1) All roles identified and people are fully aware of their role and responsibilities and there is clear documentation of this. All are fully undertaking their responsibilities. <br> <br> 2) All roles identified and people are fully aware of their role and responsibilities and there is near complete documentation of this. All are fully undertaking their responsibilities. <br> <br> 3) People are undertaking these roles, but have not been explicitly named as such or may not be undertaking all aspects of the role. <br> <br> 4) Some of the roles are being undertaken, but people not fully aware of their responsibilities. <br> <br> 5) Insufficient evidence of allocation of roles and/or the requisite activities taking place."

#----DG7----
DG7tooltipstatistics <- "1) A QA plan exists and is clearly agreed by both analytical assurer and commissioner/analysis SRO. The plan is embedded within the overall work. Time and resources have been planned to address QA recommendations. <br> <br> 2) Near complete QA plan. Plan signed off by SRO and analytical assurer. Some uncertainty over time and resources. <br> <br> 3) Some evidence of QA plan. Plan not signed off by SRO and Analytical Assurer. Lack of clarity over time and resources. <br> <br> 4) Little evidence of QA plan. <br> <br> 5) No evidence of QA plan."

#----DG8----
DG8tooltipstatistics <- "1) Clear and comprehensive record of all QA activities in the QA plan and any additional activity undertaken. The analytical assurer has scrutinised the activity and signed off. <br> <br> 2) Clear and comprehensive record of all QA activities in the QA plan and any additional activity undertaken. The analytical assurer has not yet signed off. <br> <br> 3) A record exists, but it is not clear that it covers all aspects of QA and has not been scrutinised. <br> <br> 4) Little evidence of QA record. <br> <br> 5) No evidence of QA record."

#----DG9----
DG9tooltipstatistics <- "1) Clear and comprehensive record of all risks and issues, including mitigations and details of action undertaken.  Relevant stakeholders have scrutinised the log and signed off. <br> <br> 2) Clear and comprehensive record of all risks and issues, including miitigations and details of action undertaken. Not yet signed off. <br> <br> 3) A log exists, but it is not clear that it covers all risks and/or issues and has not been scrutinised. <br> <br> 4) Little evidence of a risks and issues log. <br> <br> 5) No evidence of a risks and issues log."

#----Structure and clarity----

#----SC1----
SC1tooltipstatistics <- "1) A analysis map exists and has been used to identify possible issues with the structure. The analysis structure is clear, simple and free of unused data/formulae. <br> <br> 2) The analysis has a clear and simple structure, but a map is not available. May include a small amount of unused data/formulae. <br> <br> 3) Some issues with the structure: interactions between different parts of the analysis may not always be easy to follow and no clear distinction between inputs, calculations and outputs. May include some unused data/formulae. <br> <br> 4) Many issues about the structure: interactions between different parts of the analysis may be difficult to follow and no clear distinction between inputs, calculations and outputs. Model could include significant amounts of unused data/formulae. <br> <br> 5) Extremely complicated structure. It is not clear how different parts of the analysis interact. Model could include substantial amounts of unused data/formulae."

#----SC2----
SC2tooltipstatistics <- "1) All calculations have a clear purpose, with a clean layout and the logic is easy to follow. Coding (if used) is clear, easy to read and follows a consistent convention throughout. <br> <br> 2) All key calculations have a clear purpose, with a clean layout and the logic is easy to follow. Some minor calculation may require more effort to understand. Coding (if used) is clear and easy to read throughout and mostly follows a consistent convention. <br> <br> 3) Most calculations have a clear purpose, with a clean layout and the logic is easy to follow, but some significant calcualtions are harder to follow. Coding (if used) is generally clear and easy to read but without a consistent convention. <br> <br> 4) Significant calculations are badly structured, though they can be followed with care. Coding (if used) not always clear and lacking convention. <br> <br> 5) It is very difficult to understand the flow of calculations. Coding (if used) unclear and lacking convention."

#----SC3----
SC3tooltipstatistics <- "1) Units and labels always clearly expressed. No hardcoded values are used in conversions (eg conversion tables used). Rounding is performed correctly. <br> <br> 2) Units and labels always clearly expressed. A few hardcoded values are used in conversions. Rounding is performed correctly. <br> <br> 3) Units and labels are available in most of the cases. Some hardcoded values are used in conversions. Some rounding issues (eg inappropriate level of rounding or used in intermediate calculations) <br> <br> 4) Units or labels sometimes missing. Conversions mostly performed with hardcoded values. Some rounding issues. <br> <br> 5) Units or labels often missing. Conversions performed with hardcoded values. Significant rounding issues."

#----SC4----
SC4tooltipstatistics <- "1) Comments and explanations are embedded throughout the analysis so that it is very easy to understand formulae and methodology. Data sources are clearly identified (and linked if appropriate). <br> <br> 2)The majority of the analysis has comments embedded and these are clear but there are some cases where comments would be helpful. Almost all of the data sources are identified (and linked if appropriate). <br> <br> 3) The main parts of the analysis are commented, but some further explanations would be helpful. Not all the data sources are identified. <br> <br> 4)There are some comments but these are not clear and some are out of date. It is not possible to fully understand the analysis without talking with the analysislers. <br> <br> 5) No or very rare comments. It is very difficult to understand formulae without talking with the analysislers."

#----SC5----
SC5tooltipstatistics <- "1) Formulae are, as far as possible, easily understandable. No potential issues due to lack of formulae robustness (e.g. if changes are introduced, the analysis goes on working fine). No hardcoded values. <br> <br> 2) A robust approach is used in most of the formulae. Some minor issues, like a few hardcoded values. <br> <br> 3) Some formulae could be made more robust (e.g. by using tables or named ranges or removing the hardcoded values). <br> <br> 4) In many cases the formulae used are not the best/most robust ones. Changes in the analysis, such as the introduction of new functionalities or the change of the default setting would likely lead to issues. Hardcoded values are used extensively. <br> <br> 5) Most formulae are not clear or robust, large use of hardcoded values."

#----SC6----
SC6tooltipstatistics <- "Not required."

#----SC7----
SC7tooltipstatistics <- "1) All of the activities described below have been carried out. <br> <br> 2) Most of the activities described below have been carried out. <br> <br> 3) Some of the activities described below have been carried out. <br> <br> 4) Only one of the activities described below have been carried out. <br> <br> 5) No evidence that caveats and footnotes have been reviewed. <br> <br> * Breaks in time series clearly identified and explained; <br> * Footnotes have been used appropriately including numbering, links and references to methodology document; <br> * Titles and headers are clearly explained; <br> * Data has been correctly sourced?"

#----SC8----
SC8tooltipstatistics <- "1) All of the activities described below have been carried out. <br> <br> 2) Most of the activities described below have been carried out. <br> <br> 3) Some of the activities described below have been carried out. <br> <br> 4) Only one or two of the activities described below have been carried out. <br> <br> 5) No evidence that caveats and footnotes have been reviewed. <br> *Is the publication date consistent with the release date? Are the timeframes mentioned (month, quarter, year) up to date too? <br> *Has consistency in text and figures been used throughout the release e.g. capitalisation, use of acronyms, rounding, \"%\" vs \"per cent\"? <br> *Do all of the links work correctly? <br> *Has the answer been proof read to eliminate typing and grammatical errors? Complete a spell check <br> * Do page numbers in the content page match the actual page numbers? <br> * Do any standalone documents (e.g. methodology documents) meet GOV.UK accessibility requirements?"

#----SC9----
SC9tooltipstatistics <- "1) RAP fully implemented with full documentation in M Markdown <br> <br> 2) Production of outputs automated but documentation not yet in R Markdown (or vice versa) <br> <br> 3) Some automated production and/or some documentation  in R Markdown <br> <br> 4) Limited automation and no R MArkdown documentation <br> <br> 5) No automation or R Markdown documentation"

#----Verification----

#----VE1----
VE1tooltipstatistics <- "1) All formulae and names have been checked after the last analytical development and no issues have been found or they have all been fixed. <br> <br> 2) All the high priority formulae and names have been checked after the last analytical development and the important issues have been fixed. There is a good QA process in place to check the remaining formulae. The few minor outstanding issues are fully documented and have no impact on the results. <br> <br> 3) Most of the formulae and the names have been checked recently. Some issues are outstanding. <br> <br> 4) Most of the formulae and names have been checked recently. Some formulae or names are not correct and could have an impact on the analysis outputs. <br> <br> 5) Many formulae or names are not correct and they have a significant impact on the analysis outputs, OR very few formulae and names have been checked."

#----VE2----
VE2tooltipstatistics <- "1) The analysis is free of bugs and all the functionalities work correctly. If parts of the analysis are a work in progress, they are clearly labelled and formatted. When settings or scenarios are changed no issues occur. The runtime is appropriate. All the relevant cell protection procedures have been implemented <br> <br> 2) The analysis is free of bugs and all the functionalities work correctly. A few minor issues which dont have any impact on the analysis have been documented and explained <br> <br> 3) The main functionalities work correctly. Some issues if the non-default scenarios/settings are selected, but they have been documented. Some protection procedures implemented but a few issues occur <br> <br> 4) Routine operation works correctly, but change of scenarios/settings leads to errors. Issues with analysis runtime. Limited protection procedures and a moderate change of some major errors creeping in <br> <br> 5) There are bugs during routine operation, no protection implemented OR usability has not been checked"

#----VE3----
VE3tooltipstatistics <- "1) Auto-checking functionalities are present and correctly implemented wherever possible. <br> <br> 2)  Auto-checking functionalities correctly implemented for high priority analysis sections, but a few could be added to improve analysis quality. <br> <br> 3) There are some autochecks, but more could be introduced to easily spot errors or inconsistencies, OR only some autochecks have been examined. <br> <br> 4)  Very few autochecks implemented OR few autochecks examined. <br> <br> 5) No autochecks, OR these have not been examined."

#----VE4----
VE4tooltipstatistics <- "Not required."

#----VE5----
VE5tooltipstatistics <- "1) Output is automatically fed into dependent documentation. Extensive checking undertaken to ensure very low risk of error. <br> <br> 2) Output is automatically fed into dependent documentation. Some checking undertaken. Or analysis output is transcribed manually with comprehensive checking. <br> <br> 3) Output is automatically fed into dependent documentation. Automation has previously been checked but no additional checking for this exercise. Or analysis output is transcribed manually with some checking. <br> <br> 4) Limited checking of feed. <br> <br> 5) No checking."

#----VE6----
VE6tooltipstatistics <- "1) All of the activities described below have been carried out. <br> <br> 2) Most of the activities described below have been carried out. <br> <br> 3) Some of the activities described below have been carried out. <br> <br> 4) Only one of the activities described below have been carried out. <br> <br> 5) No evidence that caveats and footnotes have been reviewed. <br> <br> * Breaks in time series clearly identified and explained; <br> <br> * Footnotes have been used appropriately including numbering, links and references to methodology document; <br> <br> * Titles and headers are clearly explained; <br> <br> * Data has been correctly sourced?"

#----Validation----

#----VA1----
VA1tooltipstatistics <- "1) The methodology has been agreed with relevant stakeholders and reviewed by experts. The analysis produces logical outputs <br> <br> 2) The methodology is correct but only some relevant stakeholders have reviewed it. The analysis produces logical outputs <br> <br> 3) Both methodology and outputs are logical, but have not been reviewed by relevant stakeholders, OR only parts of the methodology have been reviewed since a redevelopment <br> <br> 4) Some results are counterintuitive and not all the methodology is sensible, OR very few parts of the methodology have been reviewed <br> <br> 5) Not all the outputs are logical or the methodology is not always sensible and fit for purpose, OR the methodology needs review but this has not yet happened."

#----VA2----
VA2tooltipstatistics <- "1) The analysis behaviour when historical data are used is sensible and the outputs are fairly close to the historical outputs OR the analysis has been compared against alternative data sources, with a clear explanation of any differences <br> <br> 2) Most of the outputs match historical or alternative data with a clear explanation of any differences <br> <br> 3) Historical outputs cannot be always reproduced by the analysis, but this behaviour is documented, OR only some of the feasible comparisons have been carried out. <br> <br> 4) The historical values differ significantly from the analysis outputs and the explanation for this is somewhat insufficient, OR few comparisons with historical data performed <br> <br> 5) The analysis cannot replicate the historical outputs and no explanation is available, OR no historical comparisons have been performed. <br> <br> N/A) No historical data available and no alternative data comparison is possible"

#----VA3----
VA3tooltipstatistics <- "Not required."

#----VA4----
VA4tooltipstatistics <- "1) Extreme values testing has been performed for all the relevant data. Errors due to extreme values have been identified and cell protection procedures have been implemented where appropriate so that only values in a certain range are acceptable inputs <br> <br> 2) Extreme values testing has been performed on all high risk data and results are acceptable (no significant issues) <br> <br> 3) Few extreme values tests have been performed but results are logical <br> <br> 4) Not enough testing performed OR many issues (although not critical) found when performing extreme values tests <br> <br> 5) No extreme values testing, or there are significant issues when testing extreme values <br> <br> N/A) Extreme values testing would not be helpful for the analysis"

#----VA5----
VA5tooltipstatistics <- "1) All key calculations have been reperformed and the same results have been achieved (or within acceptable tolerance level) <br> <br> 2) Key calculations have been reperformed and the same results have been achieved (or within acceptable tolerance level) <br> <br> 3) Some sections have been reperformed in a different way but the outputs differ somewhat.  However the reason behind the difference is fully understood and documented <br> <br> 4) There are some difference in the outputs and not all of them can be clearly explained <br> <br> 5) No re-performance testing implemented even if it would be feasible and beneficial to check analysis outputs, or the testing produces unacceptably different values from the analysiss outputs, OR Re-performance testing has not been reviewed <br> <br> N/A) Re-performance testing not applicable"

#----Data and assumptions----

#----DA1----
DA1tooltipstatistics <- "1) Data log containing all the relevant information about data available. Data fit for purpose, their quality, impact and risk recorded and fully understood. Data signed-off and up-to-date <br> <br> 2) Data log containing all high risk data available; data fit for purpose, their quality, impact and risk recorded and fully understood. Data signed-off and up-to-date <br> <br> 3) Data fit for purpose and Data log available but not all data are recorded and/or some information is missing. Or Data log is missing but the majority of data is recorded and information is present within the analysis. <br> <br> 4) Data log missing, but some information is available (in the documentation or within the analysis). Quality of data not always assessed properly, sign off may be missing <br> <br> 5) Data log missing and very little information available. No documentation assessing data quality and limitations and no sign off. Not all data is fit for purpose"

#----DA2----
DA2tooltipstatistics <- "1) Complete details available about where the data is taken and how it is transformed. Data matches source following transformation. <br> <br> 2) Details on data transformation are available for all critical data and sources are included <br> <br> 3) Not all the data transformations are clearly documented but no errors due to copying/pasting/transforming data <br> <br> 4) Not clear description of data transformations, some sources are not included <br> <br> 5) A proper description of how data is transformed is missing, sources are often not included. It is difficult to check whether there are errors due to copying/pasting/transforming data <br> <br> N/A) No transformation performed"

#----DA3----
DA3tooltipstatistics <- "1) Assumptions log containing all the relevant information about all the assumptions. Assumptions are fit for purpose, their quality, impact and risk recorded and fully understood. Assumptions signed-off and up-to-date <br> <br> 2) Assumptions log containing all high risk assumptions; assumptions fit for purpose, their quality, impact and risk recorded and fully understood. Assumptions signed-off and up-to-date <br> <br> 3) Assumptions fit for purpose and Assumptions log available but not all assumptions are recorded and/or some information is missing. Or assumptions log is missing but the majority of assumptions is recorded and information is present within the analysis. <br> <br> 4) Assumptions log missing, but some information is available (in the documentation or within the analysis). Quality of assumptions not always assessed properly, sign off may be missing <br> <br> 5) Assumptions log missing and very little information available. No documentation assessing assumptions quality and risk and no sign off. Not all assumptions are fit for purpose"

#----DA4----
DA4tooltipstatistics <- "Not required."